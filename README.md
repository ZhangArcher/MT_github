# MT_github
![Image text](https://github.com/ZhangArcher/MT_github/blob/master/Process.png)

Here is the repository of my master thesis.
In my master thesis , I aim at applying the data fusion methods in the portfolios optimization.


In data fusion theory , it is possible using a low-fidelity model  to simulate a high-fidelity model .
In other words, we can find a mapping function, which can map the low-fidelity model into the high-fidelity model.
And then , computing high-fidelity model can be converted into computing low-fidelity model , while the computational cost of the  low-fidelity model  is cheaper.


In this project , we try to using a short-term financial data to simulate a long-term financial data . The new financial data ,which is generated from the short-term financial data , can outperform the long-term financial data ,while using these data to do investment.

For example , short-term financial data  can be daily stock prices.
long-term data can be monthly stock prices.
we can consider daily stock prices and monthly stock prices together , describe the stock value in a new monthly stock price and decide whether or not to buy or sell a stock.

One more example is :
short-term financial data  is short-term portfolios.
long-term data is long-term portfolios.
short-term portfolio means a portfolio rebalance itself with a higher frequency.
long-term portfolio means a portfolio rebalance itself with a lower frequency.
For example, a short-term portfolio can be a daily portfolio ,which must rebalance itself every day , while a long-term portfolio can be a monthly portfolio ,which must rebalance itself every month.

The stock price and the portfolio are two different types of the financial data.

Normally,the stock price  doesn't follow a stable process.
Hence ,the stock price  can not be describe perfectly by Gaussian process.
It doesn't matter how larger data set we can get and use for the training.


The portfolio ,which is generated from the stock price  , is more complex.
The portfolio can be generated by solving some convex optimization problem.. We are trying to find the relationship among these portfolios , the result of the convex optimization problem.
The generation of portfolios need the expected returns of asset.
The expected return just means how much money we can earn after the asset purchase. But , it is unknown . We don't know how much money we can earn in the future. Hence, we need to estimate/predict the expected return.
Traditionally, the expected return is the nearby return or the last return. 




Thje project consist of 8 steps.

To do list(done):

###### 0.data collection

###### 1.stock price data handler,which can load stock price

###### 2.simple Gaussian process fitting of stock prices

###### 3.simple Gaussian process fusion for stock prices

###### 4.portfolios generation(portfolio data set generation)  based on standard / customized expected return ,risk model and objected function.

###### 5.Different Gaussian Proccess fitting of asset allocations based on the monthly prices. (just use simple kernel)

###### 6.Different Gaussian Proccess fusion of  asset allocations


to do list(unfinish):

###### 7. utilize the relationship among multi-Gaussian Process output (still being in test)


###### 8. Using Gaussian Process fusion from MuDaFuGP.




details:

# 0. data collection:

In this step , we need to collect sotck prices data ,using package yfinance , according to different time scale , for example : daily prices, monthly prices , yearly prices

    see "data_set_price/data_collect.py"

# 1. stock price data handler:
In this step , we need to create a class which can load stock prices and can return a historical prices by a time interval and stock id.

    see "data_handler_price.py"


# 2. Gaussian process fitting of stock prices

In this step , we need to fit a Gaussian process with stock prices.

Until now, the model fitting support: GPR (gaussian process regression) , VGP(Variational Gaussian Process), SGPR (Sparse Gaussian Process Regression )

gp_wrapper_prices.py can load stock prices by data_handler_price.py.

Using these stock prices , data_wrapper_gp can fit a Gaussian Process GP.

gp_wrapper_prices.py  can predict the future price by GP.

#####Term:

>**fitting_windows**: the time interval size used to fit a Gaussian Process.  A larger fitting_windows means a larger data set.

>**pred_length**: prediction length,the length of the future time what we to predict

##### Example :

  
    Suppose there are 20 trading days each month and 252 trading days each year.
    Data=The data set about the daily prices between 01.06.2000 and 01.06.2002  ( 2 years)
    
    fitting_length = the size of Data = 252*2 = 504
    
    Gaussian_Process_fit(Data)=GP

    X:= next day

    GP.predict(X) := the predicted next day stock price  (the predicted daily stock price on 02.01.2002)
    
    here , we treat the corresponding mean of GP as the predicted price.
    
    pred_Price= GP.predict(X) 

    Hence,
    pred_Price := the predicted daily stock price on 02.01.2002
    actual_Price :=the daily stock price on 02.01.2002

    Error = error_function(actual_Price,pred_Price)
    
    Error can be generated by error_function with the input (actual_Price,pred_Price)

    
    
In this section, we want to know :
whether or not using a ***larger fitting_windows*** or using a ***smaller pred_length*** can ***reduce the Error***. 


#### Experiment1-pred_lengths(see:Tutorial_notebook/Experiment1.ipynb):
    goal : test the performance with different pred_lengths.

##### data set:

    demo_data/ex1/long/MSFT.csv :
            MSFT  monthly stock price from 2000-02-01 to  2015-01-01.

##### Process:

    1.Using different pred_length(5,10,15,20,25,30) to predict the price.
    2.To compare the errors from different pred_length
    
##### error_function:
    error_function can be : pred_Price - actual_Price
    
##### result:
     see : Tutorial_notebook/ex1_pred_lengths_result.txt

Firstly, as we can see , the average error of the predicted priceror becomes larger while the pred_length is increasing.
Hence , we need to shorten the pred_length.

Secondly, we can see the  average error of the predicted price is smaller than the average error of the traditional expected price , while pred_length is 1.
The predicted price is better than the traditional expected price.

#### Experiment1-fitting_windows (see:Tutorial_notebook/Experiment1.ipynb):
    goal : test the performance with different fitting_windows.

##### data set:

    demo_data/ex1/long/MSFT.csv :
            MSFT  monthly stock price from 2000-02-01 to  2015-01-01.

##### Process:

    1.Using different fitting_windows(5,10,15,20,25,30) to predict the price.
    2.To compare the errors from different fitting_windows

##### error_function:
    error_function can be : abs(pred_Price - actual_Price)

##### result:
    see:Tutorial_notebook/ex1_fitting_windows_result.txt


Firstly,as we can see , the errors are not  decreasing while the fitting_window is  increasing.
Hence , there is not evidence to prove that we can reduce the error by using a large fitting_windows.
The minimal error is the error with fitting_windows =2 , the smallest fitting_windows.
Therefore, keeping fitting_windows smaller and smaller is the best way to reduce the error.
Secondly,all average errors of the predicted price are larger than the corresponding average errors of the traditional expected price.
The difference between two errors is smallest while fitting_windows =2 .

# 3. Gaussian process fusion for stock prices (fusion by multiple linear regression)

In this step , we predict long-term stock price with  short-term stock prices using some fusion methods.



# 3.1  fusion with  the  forward window (multiple short-term data points)
##### Example:
Here is an example about predicting long-term stock price with  short-term stock prices using some fusion methods.

Suppose we are going to predict a stock monthly price in 04.2015 with the historical stock prices data between 01.04.2014 and 31-03-2015.
Besides the historical stock prices data , we still need  a future stock price data.
The future stock price data is the stock prices between 01.04.2015 and 1-05-2015.
**(importance: our assumption is that  the stock monthly price and the stock daily price both of them are close price .
Hence , the stock monthly price in 04.2015 =  the stock daily price on 30.04.2015)**
we want to use some data fusion methods to predict the monthly price  in 04.2015.

The fusion consists of 3 steps:

***to predict the long-term data***
***to predict the short-term data with the excess time (multiple short-term data points) ***
***to fuse the long-term data with the short-term data***

#### To predict the long-term data

    In this example , the long-term data is the stock monthly price.

    We want to predict the stock monthly price in  04.2015 like in section 2 (simple Gaussian process fitting of stock prices).

    Gaussian_Process_fit(Data_monthly):= GP_long_term

    while Data_monthly is the monthly prices  from the historical stock prices data between 01.04.2014 and 31-03-2015 , and doesn't contains the monthly price in 04.2015.

    GP_long_term.predict(next_month) = pred_price_long
    while pred_price_long is the predicted next month stock price (the predicted monthly stock price in  04.2015)

#### To predict the short-term data with the forward window
    In this example , the short-term data is the stock daily prices.

    we do the similar thing like the last step, but the difference is that there is a new parameter , forward_window.

    The purpose of this example is to predict a stock monthly price in 04.2015.
    And we have known , the stock monthly price in 04.2015 is equal to the stock daily price on 30.04.2015 .
    There are 29 data points between 01.04.2015 and 29.04.2015.
    Traditional ,  we can predict the stock daily price on 30.04.2015 with the historical stock prices data between 01.04.2014 and 31-03-2015 and these 29 data points .

    But in this example , we are not going to directly predict the stock daily price on 30.04.2015 with the historical stock prices data and these 29 data points.
    We just want to predict some stock daily prices between 01.04.2015 and 29.04.2015.
    These predicted stock daily prices and the predicted stock monthly prices from the last step , are fused to make a better predicted stock monthly prices.

    forward_window means the time interval size of these data points.
    For example , let forward_window =5 ,
    It means we need to predict the stock daily prices between  [01.04.2015 ,05.04.2015]

    Here is an example how to predict a stock daily price on 03.04.2015

    Gaussian_Process_fit(Data_daily):= GP_short_term
    while Data_daily is the daily prices from the historical stock prices data between 01.04.2014 and 31-03-2015 , and the stock daily prices  between  [01.04.2015 ,02.04.2015]
    GP_short_term.predict(next_days) = pred_Price_short
    while pred_Price_short is the predicted next month stock price (the predicted monthly stock price  on 03.04.2015)


#### To fuse the long-term data with the short-term data
    In this step , we try to fuse the long-term data with the short-term data.
    The long-term data is the predicted stock monthly price in 04.2015.
    The  short-term data is the predicted stock daily prices  between [01.04.2015 ,05.04.2015].

    We are trying to finding a mapping_function , which generate a better predicted stock monthly price in 04.2015 by the long-term data and the short-term data.

    mapping_function( the long-term data, the short-term data)=a better long-term data

    Here ,a better long-term data is the fused predicted stock monthly price in 04.2015.

    The mapping_function now support :  multiple linear regression.
    A linear regression model assumes that the relationship between the dependent variable y and the vector of regressors x is linear.

   The predicted stock monthly price and the predicted stock daily prices are regarded as the vector of regressors.
   The actual stock monthly price is the dependent variable y.
   We try to fit a suitablt multiple linear regression model to fuse the  long-term data with the short-term data.



#### Experiment2-multiple short-term data points (see:Tutorial_notebook/Experiment2.ipynb)
    In this Experiment , we test how the forward_window can improve the performance of the prediction , while using Gaussian process fusion for stock prices with multiple short-term data points.
    The fusion method is based on multiple linear regression.


    data set:
        long_term_MSFT.csv : the data set about MSFT stock monthly price between 2007-01-01 and  2015-02-01 .
        short_term_MSFT.csv : the data set about MSFT stock daily price between 2007-01-01 and  2015-02-01 .

    Process:
        start_time= "01-02-2007 "
        predict_begin="-01-02-2011"
        end_time="01-02-2015"
        forward_window=[1,5,10,15,20,25]
        we want to predict the MSFT monthly price from  predict_begin  to end_time every month with different forward_window.

            The actual long term data : the actual monthly prices that we  want to predicted in step1 and step 3.
            The actual short-term data : the actuial daily prices that we have predicted in step 2.

        step1: to predict the long-term data
            the long-term data : The predicted monthly price

        step2: to predict the short-term data with the excess time (multiple short-term data points)
            the short-term data: The predicted daily prices   (data size = forward_window)

        step3: to fuse the long-term data with the short-term data , and to generate the fused data.
            let X=[the long-term data,the short-term data] ,Y^*=[the fused long term data]
            Y^*=multiple linear regression(X)

            Let Y=[the actual long term data],
            Add X and Y into the training data set to fit multiple linear regression.


        calculate the errors.

        error of fusion:
        abs(the fused long term data - the actual long term data)

        error of long_term prediction:
        abs(the long-term data - the actual long term data)

        error of short_term prediction:
        abs(the short term data[-1] - the actual long term data)

        (importance: the short term data[-1]  is the last one data point from these predicted daily prices )

    result: see:  Tutorial_notebook/ex2_multiple_short_term.txt

  ![Image text](https://github.com/ZhangArcher/MT_github/blob/linear_regression_in_fusion/Tutorial_notebook/ex2_multi.png)

As we can see ,  average error of short_term prediction is decreasing with the forward_window increasing .While forward_window >=15 ,  average error of short_term prediction is smaller than   average error of long_term prediction.
It seems that forward_window can really decrease the prediction error.

The change of the averaeg error of fusion is different from the average error of short_term prediction.
The averaeg error of fusion  increase into  5.639578695638063 at first , and then decrease into  2.9044778192285734.
Maybe the number of variable in the multiple linear regression.is too larger.




# 3.2 fusion with  forward window (single short-term data point)
##### Example:
    According to section 3.1 , we can see the error of  fusion is not enough good.
    This section , we test a modified version,a fusion with the excess time and a single short-term data point.

    We do a similar thing like in section 3.1 ,
    But we  modify step 2 and step 3

#### To predict the short-term data with the excess time (single short-term data point)
    we do the similar thing like in section 3.1.

    The purpose is to predict a stock monthly price in 04.2015.

    The only difference is that We predict just one stock daily price between 01.04.2015 and 29.04.2015.

    For example , let forward_window =5 ,
    It means we need to predict the stock daily price in  06.04.2015.
    let forward_window =15 ,
    It means we need to predict the stock daily price in  16.04.2015.


#### Experiment2-singleshort-term data points (see:Tutorial_notebook/Experiment2.ipynb)
    In this Experiment , we test how the forward_window can improve the performance of the prediction , while using Gaussian process fusion for stock prices with multiple short-term data points.
    The fusion method is based on multiple linear regression.


##### data set:
        long_term_MSFT.csv : the data set about MSFT stock monthly price between 2007-01-01 and  2015-02-01 .
        short_term_MSFT.csv : the data set about MSFT stock daily price between 2007-01-01 and  2015-02-01 .

##### Process:
        start_time= "01-02-2007 "
        predict_begin="-01-02-2011"
        end_time="01-02-2015"
        forward_window=[1,5,10,15,20,25]
        we want to predict the MSFT monthly price from  predict_begin  to end_time every month with different forward_window.

            The actual long term data : the actual monthly prices that we  want to predicted in step1 and step 3.
            The actual short-term data : the actuial daily prices that we have predicted .in step 2.

        step1: to predict the long-term data
            the long-term data : The predicted monthly price

        step2: to predict the short-term data with the excess time (multiple short-term data points)
            the short-term data: The predicted daily prices   (data size = forward_window)

        step3: to fuse the long-term data with the short-term data , and to generate the fused data.
            let X=[the long-term data,the short-term data] ,Y^*=[the fused long term data]
            Y^*=multiple linear regression(X)

            Let Y=[the actual long term data],
            Add X and Y into the training data set to fit multiple linear regression.


        calculate the errors.

        error of fusion:
        abs(the fused long term data - the actual long term data)

        error of long_term prediction:
        abs(the long-term data - the actual long term data)

        error of short_term prediction:
        abs(the short term data[-1] - the actual long term data)

        (importance: the short term data[-1]  is the last one data point from these predicted daily prices )

##### result:
     see: Tutorial_notebook/ex2_single_short_term.txt


  ![Image text](https://github.com/ZhangArcher/MT_github/blob/linear_regression_in_fusion/Tutorial_notebook/ex2_single.png)

As we can see the figure of the result ,average error of short_term is larger than average error of long_term before forward_window = 13 .
After then, average error of short_term is smaller than average error of long_term.
It means that the forward_window can improve the performance of the prediction by reduction of the prediction length.
There is similar behavior about averaeg error of fusion .
But averaeg error of fusion always be larger than average error of short_term.
It seems that the fusion algorithm can not work very well on the prediction of stock prices.



# 4.The portfolio generation based on standard / customized expected return ,risk model and objected function.
    The portfolio generation is based on PyPortfolioOpt.
    (https://pyportfolioopt.readthedocs.io/en/latest/UserGuide.html)
    The portfolios generation is focusing on mean-variance optimization (MVO).
    MVO is going to calculate/optimize a portfolio according the expected returns and the risk model (covariance matrix).
    Using PyPortfolioOpt , we can easier generate the expected returns and the covariance matrix from the historical prices.
    And then we can generate a portfolio from the expected returns and the covariance matrix by PyPortfolioOpt.
    we need to choice how to calculate/generate the expected returns , the covariance matrix and portfolio.

    option:
        calculate the expected returns :
            1.mean_historical_return   : calculate the mean of the historical returns
            2.ema_historical_return
            3.capm_return
            4......


        calculate the covariance matrix :
            1.semicovariance
            2.CovarianceShrinkage.Ledoit Wolf shrinkage
            3.sample covariance
            4.....

        calculate the portfolio:
            1.EfficientSemivariance
            2.Efficient CVaR
            3.EfficientCDaR

        objective_functions:
             L2 regularisation
             ....

        (using objective_functions , the generated portfolios can be more stable. More stable means that the position of asset doesn't not go down into 0 suddenly)

        https://pyportfolioopt.readthedocs.io/en/latest/GeneralEfficientFrontier.html#efficient-semivariance


    Our current selection is :
         the expected returns: mean_historical_return
         the covariance matrix :  semicovariance
         the portfolio:   EfficientSemivariance
         the objective_functions: L2 regularisation

    For example,
        we want to generate portfolio for stock A and stock B in 06.2010 according to the historical monthly returns .

        portfolio_generate(Data_A ,Data_B)= portfolio_AB   .
        while :
        Data_A is the historical monthly returns of stock A before 06.2010 .（except the return in 06.2010）
         Data_B is the historical monthly returns of stock B before 06.2010 .（except the return in 06.2010）
        portfolio_AB is the portfolio in 06.2010.
        We can calculate the profit of portfolio_AB according to the historical monthly return in 06.2010.

# 5. Gaussian Proccess fitting of asset allocation
In this step , we want to :
    1. to fit Gaussian Process for each asset's historical allocation
    2. to predict the corresponding allocation next time point.
    3. to prove that the predicted allocation is better than the traditional allocation (the profit of the predicted allocation is better than the profit of the traditional allocation )

The model fitting support: GPR (gaussian process regression) , VGP(Variational Gaussian Process), SGPR (Sparse Gaussian Process Regression )



    For example  (in formulas):
        we are going to optimize the allocation of stock a,b
        Suppose:
        The historical returns of stock a and b at time point i ,is Ri=(Ri_a , Ri_b).
        Portfolio is  Pi=(pi_a,pi_b)
        we can generate Pi from [R0,R1.....,R(i-1)].
        And then we can calculate the profit of Pi with Ri.
        Pi is the best portfolio for [R0,R1.....,R(i-1)] at time point i, while Ri is unknown at time point i.
        Ri is only konwn at time point (i+1) or later.
        hence , P(i+1) is the best portfolio for [R0,R1.....,Ri] at time point i+1.
        If we can predict  P(i+1) at time point t , we can knwon the best portfolio at time point i for [R0,R1.....,Ri].

        while :
         i is timestamp,
         pi_a is the position of asset a at time point i.
         pi_b is the position of asset b at time point i.

        suppose: Pi is generated by


        Let us assumpt : i=1,2,3,4


        Data_a=(p1_a,p2_a,p3_a)
        Data_b=(p1_b,p2_b,p3_b)


        GP_a=Gaussian_Process_fit(Data_a)
        GP_b=Gaussian_Process_fit(Data_b)


        GP_a.predict(i=4)=pred_p4_a
        GP_b.predict(i=4)=pred_p4_b

        pred_P4=(pred_p4_a,pred_p4_b)

        calculate_profit_by_portfolio(P3)=profit
        calculate_profit_by_portfolio(pred_P4)=pred_profit

        loss(score)=pred_profit - profit

        The ideal experiment result is: loss>0
        loss>0  means that our predicted portfolio is better than the original portfolio

        The real-life  experiment result  is :
        sometimes :loss>0
        sometimes :loss<0

    Note:  In our research , we just focus on long position. hence , pi_x >=0 .
           But pred_pi_x maybe smaller than 0 .
           Hence , we need to set all negative pred_pi_x into 0 .
           p4_a+p4_b+p4_b must be equal to 1
           But pred_p4_a+pred_p4_b+pred_p4_b  always not be 1 .
           Hence , we need to normalize (pred_p4_a,pred_p4_b,pred_p4_b).

    There are still the parameters : fitting_windows  and pred_length


#### Experiment3-pred_lengths(see:Tutorial_notebook/Experiment3.ipynb):
    goal : test the performance with different pred_lengths for asset allocation.

##### data set:
    monthly stock prices of three stocks (from "2008-01-01" to "2018-12-01")
    stock_id_list=["AAPL","NVDA","AMD"]


##### Process:
    0. let pred_length = x
    1. generate the historical return R according the monthly stock prices.
    2. generate prtfolio Pi according to R at time point i accroding to the monthly stock prices ,which are before time point i.
    3. predict portfolio [P(i+1),P(i+2),...,P(i+x)] according [P1,P2,....,Pi] by GPR
    4. compute the profit of Pi  Profit_Pi and the profit of the predicted p(i+1) , pred_Profit_Pi according R ,Pi and the predicted P(i+1)
    5. compute the loss score,

     loss score = pred_Profit_Pi - Profit_Pi
    loss score > 0 means that predicted P(i+1) is better then Profit_Pi.

    average predicted profit is the average pred_Profit_Pi at each time point
    average actual profit is the average Profit_Pi at each time point
   average score is the average score at each time point
    cumulative predicted profit is the cumulative result of pred_Profit_Pi.
    cumulative actual profit is the cumulative result of Profit_Pi.
     (here cumulative profit means : pred_Profit_P1 * pred_Profit_P2 * .....*pred_Profit_Pi)
    average score of the cumulative result= cumulative predicted profit  - cumulative actual profit
##### Result:
    see : Tutorial_notebook/ex3_pred_lengths.txt


  ![Image text](https://github.com/ZhangArcher/MT_github/blob/linear_regression_in_fusion/Tutorial_notebook/ex3_pred_length.png)

As we can see, the best average score, 0.04480896356552977,  appears in pred_length=1.
The average score is decreasing into around 0.015 in pred_length=15. and is increasing back to 0.03 in pred_length=15.
This maybe caused by the normalization of each predicted portfolio , to make sure that the sum of all positions is equal to 1 .
The average actual profit and the cumulative predicted profit are outperfomace than the actual profit.
At least until now , it seems keeping the pred_length shortest is the best choice.
And also , it shows that the to predict the portfolio using GPR can really improve the performance (profit)




#### Experiment3- fitting_windows(see:Tutorial_notebook/Experiment3.ipynb):
        data set:
        monthly stock prices of three stocks (from "2008-01-01" to "2018-12-01")
        stock_id_list=["AAPL","NVDA","AMD"]


##### process:
            0. let fitting_windows = x and pred_length=1
            1. generate the historical return R according the monthly stock prices.
            2. generate prtfolio Pi according to R at time point i
            3. predict portfolio P(i+1) according [P1,P2,....,Pi]
            4. compute the profit of Pi  Profit_Pi and the profit of the predicted p(i+1) , pred_Profit_Pi according R ,Pi and the predicted P(i+1)
            5. compute the loss ,

##### result:
    see:Tutorial_notebook/ex3_fitting_windows.txt

  ![Image text](https://github.com/ZhangArcher/MT_github/blob/linear_regression_in_fusion/Tutorial_notebook/ex3_fitting_windows.png)

As we can see, the experiment result is pretty strange.
most of the average scores  is smaller than zero, except the average score in  fitting_windows is = 3 .  It seems  that the predicted portfolio can not outperform than the actual portfolio.

Therefore ,  some larger fitting_windows are tested.

![Image text](https://github.com/ZhangArcher/MT_github/blob/linear_regression_in_fusion/Tutorial_notebook/ex3_fitting_windows_2.png)

As we can see , the change of loss score is not regular and the loss score  is going up and down.And it never be large than 0.
It looks that it can not improve the profit with the predicted the portfolio .
Now there is a question ,why the loss score is pretty good in Experiment3-pred_lengths , but very bad in Experiment3- fitting_windows.

Hence, we need some modification.


# 6. Gaussian Proccess fitting of asset allocation Version 2
In this step , we do a similar thing like last step. But a littl difference is that we use , we don't use predicted  P(i+1) at time point i , but at time point i+1. We don't predict at each time point but each pred_lendth-th time points.
And we test the performance again.




    For example  (in formulas):
    Let i is time point.
    0. let pred_length = x ,fittingLlength=k

    1. generate the historical return R according the monthly stock prices.
    (R=(R1,R2,....,Ri))

    2. generate prtfolio Pi according to returns (R(i-k)...,R(i-2),R(i-1)) at time point i
    3. predict portfolio [P(i+1),P(i+2),...,P(i+x)] according [P1,P2,....,Pi] by GPR
    4. compute the profit of P(i+1)  Profit_P(i+1) and the profit of the predicted p(i+1) , pred_Profit_P(i+1) according R.
    5. compute the loss score,
    6.repeat step.2 , but begin from  P(i+x+1)



#### Experiment4(see:Tutorial_notebook/Experiment4.ipynb):
    goal : test the performance with different pred_lengths and different fitting_lengths for asset allocation.

##### data set:
    monthly stock prices of three stocks (from "2008-01-01" to "2018-12-01")
    stock_id_list=["AAPL","NVDA","AMD"]


##### Process:
    0. let pred_length = x ,fittingLlength=k
    1. generate the historical return R according the monthly stock prices.
    2. generate prtfolio Pi according to R at time point i accroding to the monthly stock prices ,which are before time point i.
    3. predict portfolio [P(i+1),P(i+2),...,P(i+x)] according [P(i-k),P(i-k-1),....,Pi] by GPR
    4. compute the profit of P(i+1),P(i+2),...,P(i+x) , Profit , and the profit of the predicted P(i+1),P(i+2),...,P(i+x) , pred_Profit , according R

    5. compute the loss score,

     loss score = pred_Profit_Pi - Profit_Pi
    loss score > 0 means that predicted P(i+1) is better then Profit_Pi.

    average predicted profit is the average pred_Profit_Pi at each time point
    average actual profit is the average Profit_Pi at each time point
   average score is the average score at each time point
    cumulative predicted profit is the cumulative result of pred_Profit_Pi.
    cumulative actual profit is the cumulative result of Profit_Pi.
     (here cumulative profit means : pred_Profit_P1 * pred_Profit_P2 * .....*pred_Profit_Pi)
    average score of the cumulative result= cumulative predicted profit  - cumulative actual profit
##### Result:
    see : Tutorial_notebook/ex4_pred_lengths.txt
  ![Image text](https://github.com/ZhangArcher/MT_github/blob/linear_regression_in_fusion/Tutorial_notebook/ex3_fitting_windows.png)

As we can see, in most of situations, the average loss scores is decreasing     ,while the pred_length is larger than  3 or 4 , or smaler than 2.
hence ,  the smaller pred_length are used in the following research.
It is still uncertain that the relationship between the prediction and the fitting_lengths.
Just predicting the protfoilio can not outperform than the actual portfolio in most of situation.





